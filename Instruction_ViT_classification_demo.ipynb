{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt \n",
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "device='cuda:0'\n",
    "clipmodel, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "\n",
    "text_prompts = []\n",
    "label=['dog','cat']\n",
    "for classname in label:\n",
    "    texts = ['A photo of a '+classname+'.']\n",
    "    texts = clip.tokenize(texts).to(device)  # tokenize\n",
    "    class_embeddings = clipmodel.encode_text(texts)\n",
    "    class_embedding = F.normalize(class_embeddings, dim=-1).mean(dim=0).detach().cpu()\n",
    "    text_prompts.append(class_embedding)\n",
    "text_prompts = torch.stack(text_prompts, dim=1)\n",
    "text_prompts = text_prompts.transpose(1,0)\n",
    "# np.save('demo_text_feature.npy',text_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.12\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "print(timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 training takes 0:00:06 loss 2.48819\n",
      " * Acc@1 62.500  loss1.72779\n",
      "EPOCH 1 training takes 0:00:00 loss 2.39096\n",
      " * Acc@1 62.500  loss1.62505\n",
      "EPOCH 2 training takes 0:00:00 loss 1.61891\n",
      " * Acc@1 37.500  loss2.01969\n",
      "EPOCH 3 training takes 0:00:00 loss 3.18895\n",
      " * Acc@1 37.500  loss1.43756\n",
      "EPOCH 4 training takes 0:00:00 loss 2.96795\n",
      " * Acc@1 62.500  loss0.65559\n",
      "EPOCH 5 training takes 0:00:00 loss 1.35947\n",
      " * Acc@1 37.500  loss1.19269\n",
      "EPOCH 6 training takes 0:00:00 loss 1.90922\n",
      " * Acc@1 62.500  loss0.64441\n",
      "EPOCH 7 training takes 0:00:00 loss 1.61250\n",
      " * Acc@1 62.500  loss0.74937\n",
      "EPOCH 8 training takes 0:00:00 loss 1.45637\n",
      " * Acc@1 62.500  loss0.67324\n",
      "EPOCH 9 training takes 0:00:00 loss 1.34031\n",
      " * Acc@1 62.500  loss0.65628\n",
      "EPOCH 10 training takes 0:00:00 loss 1.35720\n",
      " * Acc@1 37.500  loss0.68946\n",
      "EPOCH 11 training takes 0:00:00 loss 1.40346\n",
      " * Acc@1 37.500  loss0.77397\n",
      "EPOCH 12 training takes 0:00:00 loss 1.61456\n",
      " * Acc@1 62.500  loss0.65470\n",
      "EPOCH 13 training takes 0:00:00 loss 1.51715\n",
      " * Acc@1 62.500  loss0.65734\n",
      "EPOCH 14 training takes 0:00:00 loss 1.38561\n",
      " * Acc@1 62.500  loss0.66701\n",
      "EPOCH 15 training takes 0:00:00 loss 1.39598\n",
      " * Acc@1 62.500  loss0.68386\n",
      "EPOCH 16 training takes 0:00:00 loss 1.44872\n",
      " * Acc@1 62.500  loss0.67310\n",
      "EPOCH 17 training takes 0:00:00 loss 1.42835\n",
      " * Acc@1 62.500  loss0.66422\n",
      "EPOCH 18 training takes 0:00:00 loss 1.37878\n",
      " * Acc@1 62.500  loss0.66061\n",
      "EPOCH 19 training takes 0:00:00 loss 1.37619\n",
      " * Acc@1 62.500  loss0.65718\n"
     ]
    }
   ],
   "source": [
    "#train demo\n",
    "import torch\n",
    "import instruction_ViT\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "import time\n",
    "import datetime\n",
    "from timm.data import Mixup\n",
    "import timm\n",
    "\n",
    "\n",
    "def train_one_epoch(model,epoch,loss_fn,optimizer,train_dataloader,mixup_fn):\n",
    "    model.train()\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    start = time.time()\n",
    "    end = time.time()\n",
    "\n",
    "    for samples,targets in train_dataloader:\n",
    "        samples=samples.cuda(non_blocking=True)\n",
    "        targets=targets.cuda(non_blocking=True)\n",
    "        \n",
    "        if mixup_fn is not None:\n",
    "            if len(targets) % 2 == 0:\n",
    "                samples, targets = mixup_fn(samples, targets)\n",
    "        output,output2=model(samples)\n",
    "        loss1=loss_fn(output,targets)\n",
    "        loss2=loss_fn(output2,targets)\n",
    "        loss = loss1+loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_meter.update(loss.item(), targets.size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    epoch_time = time.time() - start\n",
    "    print(f\"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))} loss {loss_meter.avg:.5f}\")\n",
    "\n",
    "\n",
    "def validate(model,loss_fn,val_dataloader):\n",
    "    loss_meter = AverageMeter()\n",
    "    acc1_meter = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images,target in val_dataloader:\n",
    "            images=images.cuda(non_blocking=True)\n",
    "            target=target.cuda(non_blocking=True)\n",
    "            _,output=model(images)\n",
    "            loss=loss_fn(output,target)\n",
    "            acc1,_ = accuracy(output, target, topk=(1,2))\n",
    "            loss_meter.update(loss.item(), target.size(0))\n",
    "            acc1_meter.update(acc1.item(), target.size(0))\n",
    "    print(f' * Acc@1 {acc1_meter.avg:.3f}  loss{loss_meter.avg:.5f}')\n",
    "\n",
    "#create dataloader\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from randaugment import RandAugment\n",
    "from PIL import Image\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "def _convert_image_to_rgb(image):\n",
    "        return image.convert(\"RGB\")\n",
    "def preprocess_img_train(n_px):\n",
    "    return Compose([\n",
    "    Resize(n_px, interpolation=BICUBIC),\n",
    "    CenterCrop(n_px),\n",
    "    _convert_image_to_rgb,\n",
    "    RandAugment(),\n",
    "    ToTensor(),\n",
    "    Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])\n",
    "class MyDataset_train(Dataset): #change for your dataset\n",
    "    def __init__(self,fold_name,lable_feature_list):\n",
    "        self.data=[]\n",
    "        self.label=[]\n",
    "        # label_index=np.arange(len(lable_feature_list))\n",
    "        # data_path='data_path'\n",
    "        # for i,fold in enumerate(fold_name):\n",
    "        #     data_path_ = os.path.join(data_path,fold)\n",
    "        #     self.data+=[os.path.join(data_path_,j) for j in os.listdir(data_path_)]\n",
    "        #     self.label+=[label_index[i] for _ in range(len(os.listdir(data_path_)))]\n",
    "        self.label=[0,0,0,0,0,1,1,1,1,1]\n",
    "        self.data=[torch.rand((3,224,224)) for _ in range(10)]\n",
    "        self.transform=preprocess_img_train(224) \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    def __getitem__(self, idx):\n",
    "        # path=self.data[idx]\n",
    "        # image=Image.open(path)\n",
    "        # image = self.transform(image)\n",
    "        image = self.data[idx]\n",
    "        label = torch.tensor(self.label[idx])\n",
    "        return image,label\n",
    "    \n",
    "def main(text_features,fold_name):\n",
    "    model = timm.create_model('instruction_vit_base_patch16_224',pretrained=True,num_classes=text_features.shape[0]).to(device)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "    lr_schedule=CosineLRScheduler(optimizer=optimizer,t_initial=10,lr_min=1e-5,warmup_t=5)\n",
    "    loss_fn= torch.nn.CrossEntropyLoss()\n",
    "    loss_fn=loss_fn.to(device)\n",
    "    mixup_fn=None\n",
    "    text_features_temp = text_features.to(device)\n",
    "    model.reset_prompt(text_features_temp)\n",
    "    for epoch in range(20):\n",
    "        mixup_fn = Mixup(\n",
    "                mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
    "                prob=0.1, switch_prob=0.5, mode='batch',\n",
    "                label_smoothing=0.1, num_classes=len(fold_name))\n",
    "        train_dataset=MyDataset_train(fold_name,text_features_temp)\n",
    "        dataloader=DataLoader(train_dataset,batch_size=4,drop_last=True)\n",
    "        train_one_epoch(model,epoch,loss_fn,optimizer,dataloader,mixup_fn)\n",
    "        validate(model,loss_fn,dataloader)\n",
    "        lr_schedule.step(epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        # if (epoch+1)%10==0:\n",
    "        #     torch.save(model, \"saved_parameters.pt\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text_features = text_prompts\n",
    "    fold_name=label\n",
    "    seed = 1234\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    main(text_features,fold_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shelton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
